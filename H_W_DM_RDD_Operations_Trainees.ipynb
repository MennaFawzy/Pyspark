{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2568221b",
      "metadata": {
        "id": "2568221b"
      },
      "source": [
        "### Import the required libraries then Create SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "65e6978c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65e6978c",
        "outputId": "e08615d7-947f-4cf8-8799-91ba8ba37621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=84075236904219919de5d055c2104b225e33f082ad586ed79f79cc4eb2021b82\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# Initialize a SparkSession\n",
        "spark = SparkSession.builder.appName(\"H_W_DM_RDD\").getOrCreate()"
      ],
      "metadata": {
        "id": "qso18C9NiU5n"
      },
      "id": "qso18C9NiU5n",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e9a7d9c6",
      "metadata": {
        "id": "e9a7d9c6"
      },
      "source": [
        "### Create and display an RDD from the following list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "409084ef",
      "metadata": {
        "id": "409084ef"
      },
      "outputs": [],
      "source": [
        "list = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25), ('J-Hope', 25), ('Suga', 26), ('Jin', 27)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(list)\n"
      ],
      "metadata": {
        "id": "v6ljI8-xjMkc"
      },
      "id": "v6ljI8-xjMkc",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "823af0d6",
      "metadata": {
        "id": "823af0d6"
      },
      "source": [
        "### Create a sample1.txt file to contain the text shown below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text content\n",
        "text_content = '''Utilitatis causa amicitia est quaesita.\n",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
        "Collatio igitur ista tenihil iuvat.\n",
        "Honesta oratio, Socratica, Platonis etiam.\n",
        "Primum in nostra nepotestate est, quid meminerimus?\n",
        "Duo Reges: constructio interrete.\n",
        "Quid, si etiam iucunda memoria est praeteritorum malorum?\n",
        "Si quidem, inquit, tollerem,'''\n",
        "\n",
        "# Create or overwrite the sample1.txt file and write the text to it\n",
        "with open('sample1.txt', 'w') as file:\n",
        "    file.write(text_content)\n",
        "\n",
        "print(\"sample1.txt has been created with the provided text.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AHwTFzyj42y",
        "outputId": "f19c44ec-0efe-4493-c457-2e85eb5da543"
      },
      "id": "4AHwTFzyj42y",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample1.txt has been created with the provided text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66668929",
      "metadata": {
        "id": "66668929",
        "outputId": "a901cdf6-8640-4e3a-dde7-693f27430b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Utilitatis causa amicitia est quaesita.\n",
            "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
            "Collatio igitur ista tenihil iuvat. \n",
            "Honesta oratio, Socratica, Platonis etiam. \n",
            "Primum in nostranepotestate est, quid meminerimus? \n",
            "Duo Reges: constructio interrete.\n",
            "Quid, sietiam iucunda memoria est praeteritorum malorum? \n",
            "Si quidem, inquit, tollerem,\n"
          ]
        }
      ],
      "source": [
        "print('''\n",
        "Utilitatis causa amicitia est quaesita.\n",
        "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
        "Collatio igitur ista tenihil iuvat.\n",
        "Honesta oratio, Socratica, Platonis etiam.\n",
        "Primum in nostranepotestate est, quid meminerimus?\n",
        "Duo Reges: constructio interrete.\n",
        "Quid, sietiam iucunda memoria est praeteritorum malorum?\n",
        "Si quidem, inquit, tollerem,''')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49249054",
      "metadata": {
        "id": "49249054"
      },
      "source": [
        "### Read sample1.txt file into RDD and displaying the first 4 elements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd= spark.sparkContext.textFile(\"sample1.txt\")\n",
        "# Collect all lines from the RDD and print them\n",
        "first_4_lines = rdd.take(4)\n",
        "for line in first_4_lines:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc2OE147mnnz",
        "outputId": "47f906e3-a580-4648-f02d-92c5d514a46b"
      },
      "id": "Rc2OE147mnnz",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilitatis causa amicitia est quaesita.\n",
            "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
            "Collatio igitur ista tenihil iuvat. \n",
            "Honesta oratio, Socratica, Platonis etiam. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0732dc1d",
      "metadata": {
        "id": "0732dc1d",
        "outputId": "0e77d860-5c2f-4128-9d03-47cdc714bd74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Utilitatis causa amicitia est quaesita.',\n",
              " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. ',\n",
              " 'Collatio igitur ista tenihil iuvat. ',\n",
              " 'Honesta oratio, Socratica, Platonis etiam. ']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f0194c12",
      "metadata": {
        "id": "f0194c12"
      },
      "source": [
        "### Count the total number of rows in RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "09f9d486",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09f9d486",
        "outputId": "e3199a3d-cd22-4a6d-ca48-fd49652de1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in the RDD: 8\n"
          ]
        }
      ],
      "source": [
        "# Count the total number of rows in the RDD\n",
        "total_rows = rdd.count()\n",
        "# Print the total number of rows\n",
        "print(\"Total number of rows in the RDD:\", total_rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c4dc87",
      "metadata": {
        "id": "e7c4dc87"
      },
      "source": [
        "### Create a function to convert the data into lower case and splitting it"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_rdd = spark.sparkContext.textFile(\"sample1.txt\")\n",
        "\n",
        "# Function to convert text to lowercase and split into words\n",
        "def lowercase_and_split(text):\n",
        "    # Convert to lowercase\n",
        "    lowercased_text = text.lower()\n",
        "    # Split into words\n",
        "    words = lowercased_text.split()\n",
        "    return words\n",
        "\n",
        "# Apply the function to the RDD\n",
        "result_rdd = text_rdd.flatMap(lowercase_and_split)\n",
        "\n",
        "# Collect and print the result\n",
        "result = result_rdd.collect()\n",
        "\n",
        "\n",
        "# Print the result\n",
        "for word in result:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82WtVPCNqtWH",
        "outputId": "fe44c9d1-9570-43c2-ede9-cd33ac8ea6cd"
      },
      "id": "82WtVPCNqtWH",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utilitatis\n",
            "causa\n",
            "amicitia\n",
            "est\n",
            "quaesita.\n",
            "lorem\n",
            "ipsum\n",
            "dolor\n",
            "sit\n",
            "amet,\n",
            "consectetur\n",
            "adipiscing\n",
            "elit.\n",
            "collatio\n",
            "igitur\n",
            "ista\n",
            "tenihil\n",
            "iuvat.\n",
            "honesta\n",
            "oratio,\n",
            "socratica,\n",
            "platonis\n",
            "etiam.\n",
            "primum\n",
            "in\n",
            "nostra\n",
            "nepotestate\n",
            "est,\n",
            "quid\n",
            "meminerimus?\n",
            "duo\n",
            "reges:\n",
            "constructio\n",
            "interrete.\n",
            "quid,\n",
            "si\n",
            "etiam\n",
            "iucunda\n",
            "memoria\n",
            "est\n",
            "praeteritorum\n",
            "malorum?\n",
            "si\n",
            "quidem,\n",
            "inquit,\n",
            "tollerem,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82cd28bc",
      "metadata": {
        "scrolled": true,
        "id": "82cd28bc",
        "outputId": "e745415f-6ab9-4b1c-a57a-fc575f88b78f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['utilitatis', 'causa', 'amicitia', 'est', 'quaesita.'],\n",
              " ['lorem',\n",
              "  'ipsum',\n",
              "  'dolor',\n",
              "  'sit',\n",
              "  'amet,',\n",
              "  'consectetur',\n",
              "  'adipiscing',\n",
              "  'elit.'],\n",
              " ['collatio', 'igitur', 'ista', 'tenihil', 'iuvat.'],\n",
              " ['honesta', 'oratio,', 'socratica,', 'platonis', 'etiam.'],\n",
              " ['primum', 'in', 'nostranepotestate', 'est,', 'quid', 'meminerimus?']]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7437d37f",
      "metadata": {
        "id": "7437d37f"
      },
      "source": [
        "### Remove the stopwords from the previous text. i.e. Remove it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358d6cd7",
      "metadata": {
        "id": "358d6cd7"
      },
      "outputs": [],
      "source": [
        "stopwords = ['a','all','the','as','is','am','an','and',\n",
        "             'be','been','from','had','I','I’d','why','with']\n",
        "# Hint: you may need use flatMap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text data from \"sample1.txt\" into an RDD\n",
        "text_removestop = spark.sparkContext.textFile(\"sample1.txt\")\n",
        "\n",
        "# List of stopwords (you can expand this list with more stopwords)\n",
        "stopwords = ['a','all','the','as','is','am','an','and',\n",
        "             'be','been','from','had','I','I’d','why','with']\n",
        "\n",
        "# Function to remove stopwords, convert to lowercase, and split text\n",
        "def preprocess_text(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "    # Remove stopwords, convert to lowercase, and join back into text\n",
        "    cleaned_text = \" \".join([word.lower() for word in words if word.lower() not in stopwords])\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the function to the RDD\n",
        "result_rdd = text_removestop.map(preprocess_text)\n",
        "\n",
        "# Split the cleaned text into words\n",
        "split_result_rdd = result_rdd.flatMap(lambda text: text.split())\n",
        "\n",
        "# Collect and print the result\n",
        "result = split_result_rdd.collect()\n",
        "\n",
        "# Print the result\n",
        "for word in result:\n",
        "    print(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR9sZHBtsXHS",
        "outputId": "afdbc367-2236-4f4f-d331-75a15ab8674e"
      },
      "id": "JR9sZHBtsXHS",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "utilitatis\n",
            "causa\n",
            "amicitia\n",
            "est\n",
            "quaesita.\n",
            "lorem\n",
            "ipsum\n",
            "dolor\n",
            "sit\n",
            "amet,\n",
            "consectetur\n",
            "adipiscing\n",
            "elit.\n",
            "collatio\n",
            "igitur\n",
            "ista\n",
            "tenihil\n",
            "iuvat.\n",
            "honesta\n",
            "oratio,\n",
            "socratica,\n",
            "platonis\n",
            "etiam.\n",
            "primum\n",
            "in\n",
            "nostra\n",
            "nepotestate\n",
            "est,\n",
            "quid\n",
            "meminerimus?\n",
            "duo\n",
            "reges:\n",
            "constructio\n",
            "interrete.\n",
            "quid,\n",
            "si\n",
            "etiam\n",
            "iucunda\n",
            "memoria\n",
            "est\n",
            "praeteritorum\n",
            "malorum?\n",
            "si\n",
            "quidem,\n",
            "inquit,\n",
            "tollerem,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a03bf98",
      "metadata": {
        "id": "7a03bf98",
        "outputId": "d38ae6f7-e4b9-4bcd-a7ba-7a328ce843df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['utilitatis',\n",
              " 'causa',\n",
              " 'amicitia',\n",
              " 'est',\n",
              " 'quaesita.',\n",
              " 'lorem',\n",
              " 'ipsum',\n",
              " 'dolor',\n",
              " 'sit',\n",
              " 'amet,',\n",
              " 'consectetur',\n",
              " 'adipiscing',\n",
              " 'elit.',\n",
              " 'collatio',\n",
              " 'igitur',\n",
              " 'ista',\n",
              " 'tenihil',\n",
              " 'iuvat.',\n",
              " 'honesta',\n",
              " 'oratio,',\n",
              " 'socratica,',\n",
              " 'platonis',\n",
              " 'etiam.',\n",
              " 'primum',\n",
              " 'in',\n",
              " 'nostranepotestate',\n",
              " 'est,',\n",
              " 'quid',\n",
              " 'meminerimus?',\n",
              " 'duo',\n",
              " 'reges:',\n",
              " 'constructio',\n",
              " 'interrete.',\n",
              " 'quid,',\n",
              " 'sietiam',\n",
              " 'iucunda',\n",
              " 'memoria',\n",
              " 'est',\n",
              " 'praeteritorum',\n",
              " 'malorum?',\n",
              " 'si',\n",
              " 'quidem,',\n",
              " 'inquit,',\n",
              " 'tollerem,']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb9f6058",
      "metadata": {
        "id": "fb9f6058"
      },
      "source": [
        "*italicized text* Find the words starting with ‘c’"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_words_starting_with_c(line):\n",
        "    # Convert to lowercase, split into words, and filter words starting with 'c'\n",
        "    words = line.lower().split()\n",
        "    c_words = [word for word in words if word.startswith('c')]\n",
        "    return c_words\n",
        "\n",
        "# Apply the filter operation to find words starting with 'c' in each line\n",
        "c_words_rdd = rdd.flatMap(find_words_starting_with_c)\n",
        "\n",
        "# Collect and display the words starting with 'c'\n",
        "c_words = c_words_rdd.collect()\n",
        "\n",
        "# Print the words starting with 'c'\n",
        "for word in c_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APwAo44JvQ23",
        "outputId": "f1d12808-6437-421b-9dd2-b928cc81e578"
      },
      "id": "APwAo44JvQ23",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "causa\n",
            "consectetur\n",
            "collatio\n",
            "constructio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6407c39b",
      "metadata": {
        "id": "6407c39b",
        "outputId": "59281415-a957-4463-dd93-2afd98596d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['causa', 'consectetur', 'collatio', 'constructio']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eba39e2e",
      "metadata": {
        "id": "eba39e2e"
      },
      "source": [
        "### Reduce the data by key and sum it (use the data from the following list)\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ae551b82",
      "metadata": {
        "id": "ae551b82"
      },
      "outputs": [],
      "source": [
        "list = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25)\n",
        "        , ('J-Hope', 25), ('Suga', 26), ('Jin', 27)\n",
        "       , ('J-Hope', 12), ('Suga', 25), ('Jin', 34)\n",
        "       , ('JK', 32), ('V', 44), ('Jimin',14), ('RM', 35)]\n",
        "# Hint: use reduceByKey"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_yOYCK9wWTC"
      },
      "id": "Y_yOYCK9wWTC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "rdd = spark.sparkContext.parallelize(list)\n",
        "\n",
        "# Use reduceByKey to sum values for each key\n",
        "summed_rdd = rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Collect and display the result\n",
        "result = summed_rdd.collect()\n",
        "\n",
        "# Print the summed data\n",
        "for key, value in result:\n",
        "    print(f'{key}: {value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a463b4-41f7-4397-8c7c-1fb3d1d43ce7",
        "id": "70Dnmub8wZit"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suga: 51\n",
            "Jin: 61\n",
            "JK: 54\n",
            "V: 68\n",
            "Jimin: 38\n",
            "RM: 60\n",
            "J-Hope: 37\n"
          ]
        }
      ],
      "id": "70Dnmub8wZit"
    },
    {
      "cell_type": "markdown",
      "id": "a4587230",
      "metadata": {
        "id": "a4587230"
      },
      "source": [
        "### Creat some key value pairs RDDs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = spark.sparkContext.parallelize([('a',2),('b',3)])\n",
        "rdd2 = spark.sparkContext.parallelize([('a',9),('b',7),('c',10)])"
      ],
      "metadata": {
        "id": "AaBvPwA7xO3N"
      },
      "id": "AaBvPwA7xO3N",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXP1NfWgxVn7",
        "outputId": "492d5171-78f6-470a-e13c-77cc2fb0e4d2"
      },
      "id": "jXP1NfWgxVn7",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2), ('b', 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yntYi1lxcoB",
        "outputId": "af700198-ddd6-45e6-83af-2d585dc9691a"
      },
      "id": "_yntYi1lxcoB",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 9), ('b', 7), ('c', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ef9f47",
      "metadata": {
        "id": "e4ef9f47",
        "outputId": "85104c74-fbf8-4193-c39e-db07fedc71c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('a', 2), ('b', 3)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d16f7ae9",
      "metadata": {
        "id": "d16f7ae9",
        "outputId": "7c0c786a-b433-4b21-dcf9-c1108f13bfda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('a', 9), ('b', 7), ('c', 10)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "98ec3168",
      "metadata": {
        "id": "98ec3168"
      },
      "source": [
        "### Perform Join operation on the RDDs (rdd1,rdd2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61b5926",
      "metadata": {
        "id": "c61b5926",
        "outputId": "b4a698d9-5044-4572-d2c2-8574b45b59fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('b', (3, 7)), ('a', (2, 9))]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5fc98e9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc98e9f",
        "outputId": "f3abfcca-09ba-4ebe-a6c7-32492fd48179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('b', (3, 7)), ('a', (2, 9))]\n"
          ]
        }
      ],
      "source": [
        "joined_rdd = rdd1.join(rdd2)\n",
        "result = joined_rdd.collect()\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}